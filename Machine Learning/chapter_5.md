# 第5章 神经网络

参考课程链接：【【吃瓜教程】《机器学习公式详解》（南瓜书）与西瓜书公式推导直播合集】 https://www.bilibili.com/video/BV1Mh411e7VU/?p=8&share_source=copy_web&vd_source=c22abe8e67e193936015d5ca043a8148

# 5.1 神经元模型

## 1.人工神经元的数学模型

给定输入 $x_1,x_2,...,x_n$ 和相应的权重 $w_1,w_2,...,w_n$，神经元的输出可以通过以下步骤得到：

1. **加权和**：计算输入和权重的加权和 $z=w_1x_1+w_2x_2+...+w_nx_n+b$ 其中 $b$ 是偏置项。
2. **激活函数**：将加权和通过一个函数，通常称为激活函数，例如 sigmoid、ReLU (Rectified Linear Unit)、tanh 等。这样可以将线性函数转化为非线性，使得神经网络可以表示和学习复杂函数。 $a=f(z)$ 其中 $a$ 是神经元的输出，$f$ 是激活函数。

## 2. 为什么需要激活函数？

使用激活函数的目的是为了引入非线性。如果我们只使用线性操作，无论神经网络有多少层，它最终都只能表示线性函数。通过引入非线性激活函数，神经网络就可以表示更为复杂的函数。

## 3. 常用的激活函数

- **Sigmoid**：$\sigma(z)=\frac{1}{1+e^{-z}}$，输出范围在0到1之间。
- **Tanh**：$f(z)=\frac{e^x-e^{-x}}{e^x+e^{-x}}$ 取值范围在-1到1之间。
- **ReLU (Rectified Linear Unit)**：$f(z)=max(0,z)$，对于正值直接输出，对于负值输出0。
- **Leaky ReLU, Parametric ReLU**：这是ReLU的变种，允许负值有一个小的正斜率。
- **Softmax**：常用于分类问题的输出层，可以将一组数转化为一个概率分布。

当多个这样的神经元组合在一起，并以某种结构（如前馈、循环、卷积结构等）连接时，就构成了所谓的神经网络。

## 4. 其他神经元模型

除了常见的基于加权和和激活函数的感知器（Perceptron）或被称为MP（McCulloch-Pitts）神经元模型外，还有其他的神经元模型。其中，一些模型尝试更接近地模拟生物神经元的行为。以下是一些不同的神经元模型：

1. **Hodgkin-Huxley模型**：这是一个基于详细生物实验的模型，描述了真实神经元如何根据输入电流生成动作电位（或"脉冲"）的过程。这个模型使用了复杂的微分方程来描述电流和电压之间的关系。
2. **Integrate-and-Fire模型**：这是一个相对简化的模型，其中神经元不断累积其输入，直到它达到某个阈值，此时它会发放一个脉冲并重置其内部状态。
3. **Spiking Neural Networks (SNNs)**：这类网络使用模型如Integrate-and-Fire或其他更复杂的脉冲模型作为它们的神经元。与传统的神经网络不同，SNNs中的神经元通过脉冲序列进行通信，而不是固定的激活值。
4. **Radial Basis Function (RBF) 神经元**：这种神经元的输出基于其输入与某个中心点的欧几里得距离。它们常用于RBF网络中，这种网络在某些任务，如函数逼近中，特别有效。
5. **Sigma-Pi神经元**：这种神经元可以处理二阶或更高阶的交互输入，这意味着它不仅考虑单个输入的加权和，还考虑输入之间的乘积。

这些只是神经元模型的一些例子。在实践中，简单的MP神经元（与适当的激活函数）和它的变种仍然是最常用的，因为它们为大多数应用提供了足够的表达能力，同时保持了计算效率。然而，在某些特定的应用和研究领域，例如那些需要模拟更生物真实的神经动力学的场景，其他模型可能会更为有用。

# 5.2 感知机与多层网络

## 感知机

感知机（Perceptron）是早期神经网络和机器学习的基础模型之一，由Frank Rosenblatt在1957年提出。感知机是一种线性分类器，也可以看作是单个神经元模型，它的主要用途是进行二元分类。下面是感知机的基本概念：

### 1. 模型结构

- **输入**：感知机接收一个实数向量作为输入，记为 $\boldsymbol x=(x_1,x_2,...,x_n)$。
- **权重与偏置**：感知机有一个权重向量 $\boldsymbol w=(w_1,w_2,...,w_n)$ 和一个偏置项 $b$。
- **输出**：感知机计算输入与权重的加权和，并加上偏置。然后，这个值通过一个激活函数（通常是一个阶跃函数）进行处理，输出结果通常为1或-1。

### 2. 数学公式

感知机的输出定义为：

$y=f(\boldsymbol {w·x}+b)$

其中，

- $\boldsymbol {w·x}$ 是权重和输入的点积。
- $f$ 是激活函数。在原始的感知机中，这是一个阶跃函数，定义为：

$f(z)=\begin{cases}
 \ 1 & \text{ if } z>0 \\
 -1 & \text{ otherwise } 
\end{cases}$

### 3. 学习算法

感知机的学习算法是一种迭代方法，用于逐步调整权重和偏置，使模型能够正确分类训练数据。具体步骤如下：

1. 初始化权重和偏置为零或小的随机值。
2. 对于训练集中的每个样本，计算感知机的输出。
3. 如果输出错误，则对于每一个权重 $w_i$，更新：$w_i=w_i+\eta (y-\hat y)x_i$ 其中，$\eta$ 是学习率，$y$ 是真实的目标值，而 $\hat y$ 是感知机的输出。
4. 重复第2和第3步直到所有训练数据都被正确分类或达到预设的迭代次数。

需要注意的是，感知机只能对线性可分的数据进行正确分类。对于非线性可分的数据，感知机学习算法将无法找到一个能够正确分类所有训练样本的解决方案。

## 多层网络

多层网络，通常被称为多层感知机（MLP，Multi-Layer Perceptron），是一种前馈神经网络。尽管其名称中包含“感知机”，但MLP并不仅限于单个感知机。它实际上是由多个层组成的，每层都有多个神经元，并且可以使用多种激活函数，而不仅仅是感知机中的阶跃函数。

MLP的基本结构如下：

1. **输入层**：这一层对应于模型的输入特征。例如，对于一个具有28x28像素的图像，输入层可能有784个神经元（不计算偏置）。
2. **隐藏层**：在输入层和输出层之间可以有一个或多个隐藏层。每个隐藏层可以有任意数量的神经元。隐藏层的存在使得MLP可以学习和表示非线性函数。
3. **输出层**：输出层的神经元数量与特定任务的输出相关。例如，对于一个10类分类问题，输出层可能有10个神经元。
4. **激活函数**：尽管原始的感知机使用阶跃函数，但MLP中的神经元通常使用其他激活函数，如sigmoid、tanh或ReLU，以引入非线性性质。

MLP的工作原理是通过一系列的线性组合和非线性激活函数来处理输入数据，使其能够学习并表示从输入到输出的复杂函数映射。当MLP有足够多的隐藏单元和层时，它可以近似任何连续函数，这是其强大的表达能力的来源。

为了训练MLP，常用的算法是反向传播（Backpropagation），它结合了损失函数的梯度下降优化。通过这种方式，MLP可以根据训练数据自动调整其权重，以最小化预测错误。

尽管MLP是深度学习领域的基础，但现代的深度学习应用中，更复杂的网络结构（如卷积神经网络、循环神经网络等）已经变得更为流行，因为它们在某些任务上提供了更好的性能和效率。但了解MLP仍然是理解这些更复杂模型的基础。

# 5.3 误差逆传播算法

误差逆传播算法（Error Backpropagation Algorithm），简称“反向传播”（Backpropagation）或“Backprop”，是训练多层前馈神经网络（如多层感知机，MLP）的最常用方法。该算法基于链式法则，递归地计算损失函数关于每一权重的梯度，从输出层到输入层。

反向传播是一种监督学习算法，需要一个标签或真实值来与网络的预测进行比较，并据此调整网络的权重。

以下是反向传播算法的基本步骤：

1. **前向传播**：
   - 从输入层开始，将数据送入网络。
   - 计算每一层的加权输入和激活输出，直到得到输出层的预测结果。
2. **计算误差**：
   - 在输出层，根据真实标签和网络预测，使用损失函数（如均方误差、交叉熵等）来计算误差。
3. **反向传播误差**：
   - 对于网络中的每一个权重，计算损失函数关于该权重的梯度。这是通过应用链式法则递归地从输出层向输入层完成的。
   - 每层的误差可以用更高层的误差和当前层的权重来计算。这意味着误差是从输出层“反向传播”到输入层的。
4. **权重更新**：
   - 有了损失函数关于每个权重的梯度后，可以使用梯度下降或其变种（如带动量的梯度下降、Adam等）来更新网络的权重。
   - 更新公式可能是这样的：$W=W-\eta \nabla_WL$ 其中，$\eta$ 是学习率， $L$是损失函数，$\nabla_W L$ 是损失函数关于权重 $W$ 的梯度。
5. **迭代**：
   - 重复上述步骤多次，通常是多个训练周期（epochs），直到网络的性能满足要求或不再明显改善。

反向传播提供了一种高效的方式来为深度神经网络计算梯度。在深度学习的发展历程中，反向传播算法起到了关键作用，使得多层网络的训练变得可能，并为当今的深度学习模型打下了基础。

# 5.4 全局最小与局部极小

当我们试图最小化（或最大化）一个函数时，通常会遇到两种主要的极值点：局部极小值和全局极小值。

## **局部极小值（Local Minimum）**

- 一个函数 $f(x)$ 在点 $x_0$ 处有一个局部极小值，如果存在一个非零的小区间，使得对于该区间内的所有点 $x$，都有 $f(x_0)\le f(x)$。简单地说，如果在某个点的附近，该点的函数值小于或等于其邻域内的所有其他点的函数值，那么该点就是一个局部极小值。
- 在优化的过程中，特别是在非凸函数的优化中，存在多个局部极小值是很常见的。

## **全局极小值（Global Minimum）**

- 一个函数 $f(x)$ 在点 $x_0$ 处有一个全局极小值，如果对于函数定义域内的所有点 $x$，都有 $f(x_0)\le f(x)$。也就是说，全局极小值是函数在其整个定义域中的最小值点。
- 对于凸函数，任何局部极小值都是全局极小值。但在非凸函数中，局部极小值不一定是全局极小值。

在深度学习和神经网络训练中，目标函数（通常是损失函数）往往是高度非凸的，这意味着它可能有多个局部极小值、鞍点和其他复杂的优化结构。这使得寻找全局最小值变得非常具有挑战性。但有趣的是，实践中发现即使只达到某个局部最小值或接近于局部最小值，神经网络仍然可以表现得很好。

为了避免陷入不良的局部极小值，研究者采用了各种优化策略和技术，例如使用动量、学习率衰减、随机梯度下降、Adam优化器等。

## 优化：全局最小

### 随机梯度下降 (SGD) 和 Mini-Batch SGD

随机梯度下降（Stochastic Gradient Descent, SGD）是一种迭代优化算法，主要用于优化机器学习和深度学习模型的损失函数。与传统的批量梯度下降相比，SGD每次只使用一个训练样本来计算梯度并更新模型参数。这种随机性有助于SGD跳出局部极小值并可能更快地收敛，但同时也可能导致更大的更新方差。

#### SGD的核心思想

SGD每次使用一个样本来估计整个数据集的梯度。由于此估计具有固有的随机性，更新也是随机的，这解释了"随机"这一名称。这种随机性可以帮助算法逃离局部极小值，并可能导致更快的收敛，但它也可能导致收敛到的解有噪声。

#### 算法步骤

1. 随机初始化模型的权重（参数）。
2. 对于每一个训练周期（epoch）：
   - 打乱训练数据集。
   - 对于训练集中的每一个样本：
     - 计算该样本对于损失函数的梯度。
     - 使用此梯度更新权重。

#### 伪代码

```
function SGD(training_data, learning_rate, epochs):
    weights = initialize_weights()
    for epoch in range(epochs):
        shuffle(training_data)
        for sample in training_data:
            gradient = compute_gradient(sample, weights)
            weights = weights - learning_rate * gradient
    return weights
```

#### SGD的变体

虽然基本的SGD算法只使用一个样本来计算梯度，但在实践中，通常使用**mini-batch SGD**。在这个变体中，不是使用单个样本，而是使用小批量的样本来估计梯度。这允许利用矩阵运算的优势，通常可以更快地进行训练，同时仍保持了一定的随机性。

#### SGD的优点

1. 由于频繁的权重更新，SGD往往能够更快地收敛。
2. 随机性有助于跳出局部极小值。
3. 对于大数据集，SGD不需要在每次迭代中使用所有数据。

#### SGD的缺点

1. 由于其高度的随机性，SGD可能会导致权重更新非常不稳定，这可能需要较小的学习率和/或其他技术来缓解。
2. 可能不会收敛到最优解，而只是围绕最优解摆动。
3. 对于非凸函数，如深度神经网络，可能会收敛到不良的局部极小值或鞍点，尽管实践中这并不总是问题。

由于SGD的这些挑战，很多改进和扩展已经被提出，例如Momentum、AdaGrad、RMSProp、Adam等，这些方法试图减少SGD在参数空间中的摆动并加速收敛。

### 动量 (Momentum)

动量（Momentum）是优化算法中的一个技巧，尤其用于加速神经网络训练的随机梯度下降（SGD）。动量的灵感来源于物理学，模拟了一个小球在山谷中下坡的情况，小球会积累动量，在向下的方向上加速，并在上坡时减速。

#### 动量的核心思想

在传统的SGD中，权重的更新完全取决于每次的计算梯度。但在动量方法中，权重的更新考虑了之前的权重更新，这样可以增加权重更新的连续性和稳定性。

动量考虑了之前梯度的“历史”，并将其结合到当前的梯度中，从而使连续的更新方向更加稳定。

#### 数学表达

如果用$v$表示权重的“速度”（权重更新的方向和幅度），则动量可以这样描述：

1. $v_t=\beta *v_{t-1}+(1-\beta)*gradient$
2. $weights=weights-learning\_rate*v_t$

其中：

- $\beta$是动量系数，通常设置在[0.8, 0.9]之间。
- $v_{t-1}$是前一次的权重更新。
- $gradient$是当前的梯度。

#### 伪代码

```
v = 0  // 初始化速度
beta = 0.9  // 动量系数
learning_rate = 0.01

for epoch in range(epochs):
    for mini_batch in training_data:
        gradient = compute_gradient(mini_batch)
        v = beta * v + (1-beta) * gradient
        weights = weights - learning_rate * v
```

#### 动量的优点

1. **稳定性**：动量有助于稳定梯度的方向，减少SGD中的振荡。
2. **加速**：在损失函数的某些区域中（尤其是扁平区域），动量可以加速训练，因为它“积累”了前面的梯度。
3. **避免陷入局部极小值**：动量可能帮助算法越过某些局部极小值和鞍点。

#### 动量的缺点

​	**额外的超参数**：需要选择一个合适的动量系数$\beta$。

#### 总结

动量是训练深度学习模型时常用的一个技巧，它解决了纯SGD中的一些问题，使权重更新更加平滑，可以加速收敛，并有助于避免陷入不良的局部极小值。许多现代的优化算法，如Adam、RMSprop等，都结合了动量的概念。

### 模拟退火 (Simulated Annealing)

**模拟退火（Simulated Annealing, SA）**是一种全局优化算法，灵感来源于固体材料学中的退火过程。在物理学中，退火是指将物质加热到高温，然后缓慢冷却，以达到材料的低能量状态。模拟退火算法正是模拟这一过程来寻找函数的全局最小值。

#### 基本思想

模拟退火算法的核心思想是允许在搜索过程中接受比当前解更差的解。这个“接受差解”的策略有助于算法跳出局部最小值。随着时间的推移，接受差解的可能性会减小，使得算法逐渐趋向于稳定状态。

#### 算法步骤

1. **初始化**：选择一个初始解和一个初始温度。
2. **重复以下步骤**： a. 在当前解的邻域中随机选择一个新解。 b. 计算新解与当前解之间的代价差异。 c. 如果新解更好，或者满足某种基于温度和代价差异的随机条件，则接受新解作为当前解。 d. 降低温度（按照预定的降温策略）。
3. 当温度低于某个阈值或达到预定的迭代次数后，停止算法。

#### 伪代码

```
function simulated_annealing(initial_solution, initial_temperature, cooling_rate):
    current_solution = initial_solution
    current_temperature = initial_temperature
    
    while current_temperature > threshold:
        new_solution = get_neighbor(current_solution)
        cost_difference = cost(new_solution) - cost(current_solution)
        
        if cost_difference < 0 or random(0, 1) < exp(-cost_difference / current_temperature):
            current_solution = new_solution
        
        current_temperature = current_temperature * cooling_rate
    
    return current_solution
```

#### 注意事项

1. **温度调度**：降温策略（cooling schedule）是模拟退火算法的关键部分。温度应该足够慢地降低，以确保算法有充足的时间探索解空间并收敛到全局最小值。
2. **接受准则**：即使新解不如当前解，也有可能被接受，这一概率是基于当前温度和两个解之间的代价差异来确定的。
3. **邻域选择**：如何定义和随机选择“邻居”解是另一个关键部分。它决定了搜索空间的探索方式。

#### 优点

- 可以解决一些复杂的优化问题。
- 有能力避免局部最小值，寻找全局最小值。

#### 缺点

- 需要调整的超参数较多，如初始温度、降温策略等。
- 对于某些问题，可能需要长时间的运行才能获得好的结果。

### Genetic Algorithms

遗传算法（Genetic Algorithm, GA）是一种启发式搜索优化算法，其灵感来源于自然界的生物进化过程，如遗传、突变、交叉（杂交）和自然选择等现象。遗传算法常被用于寻找对复杂问题的近似解。

#### 基本思想

遗传算法模拟了生物进化的过程，试图从一群可能的解中逐渐进化出最优解或接近最优的解。它利用了基因型（代表解的编码方式）和表现型（解的实际形态或性能）之间的映射关系。

#### 算法步骤

1. **初始化**：生成一个初始种群，种群中的每个个体表示一个可能的解。
2. **选择**：基于适应性函数评估每个个体的适应度，并选择更适应的个体进行后续的交叉和变异操作。
3. **交叉（杂交）**：模拟遗传的重组，通过组合两个个体的基因来产生新的后代。
4. **变异**：模拟生物突变，随机地改变一个个体的某些基因，为种群引入新的特性。
5. **替代**：用新生成的后代替换当前种群中的某些个体，形成新的种群。
6. **终止**：满足某些终止条件（如迭代次数、适应度达到某个阈值等）时，结束算法。

#### 伪代码

```
pseudoCopy codefunction genetic_algorithm():
    population = initialize_population()
    best_solution = get_best(population)
    
    while not termination_condition():
        parents = select_parents(population)
        offspring = []

        for pair in parents:
            child1, child2 = crossover(pair[0], pair[1])
            offspring.append(mutate(child1))
            offspring.append(mutate(child2))
        
        population = replace_population(population, offspring)
        current_best = get_best(population)
        
        if fitness(current_best) > fitness(best_solution):
            best_solution = current_best
    
    return best_solution
```

#### 特点

1. **编码方式**：解可以被编码为二进制串、整数串、实数串或其他数据结构。
2. **选择机制**：常用的选择策略有轮盘赌选择、竞技场选择和锦标赛选择等。
3. **交叉和变异**：这两个操作是为种群引入多样性的主要手段。交叉策略（如单点交叉、多点交叉）和变异策略（如位反转）可能会根据问题特性和编码方式而变化。

#### 优点

- 对于复杂的、没有已知解的问题，遗传算法提供了一种实用的全局搜索方法。
- 并不需要问题的任何数学特性或梯度信息。
- 很容易与其他搜索策略结合。

#### 缺点

- 没有保证找到全局最优解，只能得到近似解。
- 需要调整许多参数，如交叉率、变异率等。
- 对于某些问题，可能比其他优化技术效率低。

值得注意的是，实际上，在深度学习中，纯粹的局部极小值可能并不是一个主要问题。很多研究指出，对于高维非凸优化问题，如深度神经网络，更常见的问题是鞍点，而不是局部极小值。这些策略和技术也有助于避免鞍点问题。

# 5.5 其他常见神经网络

书中介绍的网络包括：RBF网络、ART网络、SOM网络、级联相关网络、Elman网络、Boltzmann机

# 5.6 深度学习

深度学习涉及的模型通常包括多层的神经网络结构，其中每一层都从前一层中学习到的表示中进一步提取抽象特征。这种层次化的表示学习方法使得深度模型在许多任务上（如图像和语音识别）比传统的浅层模型具有更高的性能。

**特点**:

1. **自动特征学习**: 深度学习模型可以自动学习数据的层次化表示，而不需要人为地设计或选择特征。
2. **多层结构**: 模型包含多个处理层，能够学习到从低级到高级的各种抽象表示。
3. **端到端学习**: 直接从原始数据中学习任务相关的表示和决策，而无需分阶段处理或手工特征工程。

### 1. 预训练-微调 (Pre-training and Fine-tuning)

**核心思想**:

- 首先，在一个大型的、通常是公共的数据集（例如ImageNet）上训练一个深度模型，这个阶段被称为预训练。
- 接下来，使用一个与特定任务相关的小数据集对预训练的模型进行微调，以适应该任务。

**优势**:

- 预训练过程可以帮助模型学习到数据的通用特征。
- 微调使模型能够利用这些通用特征，并为特定任务进行特定的调整，尤其是当目标数据集相对较小时。

**应用场景**:

- 这种方法在各种领域都非常有效，如计算机视觉、自然语言处理等。例如，在NLP领域，BERT和GPT等模型首先在大型文本数据上进行预训练，然后可以被微调到各种下游任务，如情感分析、问答等。

### 2. 权重共享 (Weight Sharing)

**核心思想**:

- 在模型的多个部分使用相同的参数或权重。

**优势**:

- 减少了模型的参数数量，从而降低了计算和存储开销。
- 通过强制模型的部分结构共享参数，可以提高模型的泛化能力，并降低过拟合的风险。

**应用场景**:

- **卷积神经网络 (CNN)**: 在CNN中，卷积滤波器在整个输入图像上滑动，共享其权重。这不仅减少了模型的参数数量，还使模型对图像的不同位置具有平移不变性。
- **循环神经网络 (RNN)**: 在RNN中，对序列的每一个时间步都使用相同的权重，这样可以处理任意长度的序列，并确保模型对序列的不同位置具有相同的处理方式。

这两种策略在许多深度学习应用中都已经被证明是非常有效的。预训练-微调策略利用了大型数据集上学习到的知识，以帮助模型在特定任务上获得更好的性能，而权重共享则是通过减少参数数量来提高计算效率和模型泛化能力。