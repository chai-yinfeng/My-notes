# 2.1 经验误差与过拟合

## 概念

经验误差与泛化误差是机器学习中两个关键的概念，它们与模型的训练及其在新数据上的性能密切相关。

### 1. **经验误差 (Empirical Error)**

经验误差又被称为训练误差，是机器学习模型在训练数据集上的误差。具体来说，它是模型在训练数据上的预测与实际目标值之间的差异的平均值。

### 2. **泛化误差 (Generalization Error)**

泛化误差是模型在新、未见过的数据上的预期误差。它表示模型对新输入数据的预测与实际目标值之间的差异。泛化误差是机器学习研究的中心议题，因为它与模型在实际应用中的性能密切相关。

## **经验误差与泛化误差的关系**

理想情况下，我们希望模型在训练数据上有低的经验误差，并且在新数据上有低的泛化误差。然而，仅仅追求低的经验误差并不总是导致低的泛化误差。一个典型的例子是过拟合：

- **过拟合**：如果模型过于复杂，它可能会在训练数据上达到非常低的经验误差（甚至为零），但在新数据上的性能却很差。这是因为模型记住了训练数据中的噪声或特定细节，而这些细节在新的数据中可能并不存在。

### **追求更小的泛化误差的过程中，对经验误差的需求**

1. **权衡**：我们需要在经验误差和模型复杂度之间找到一个平衡。简单的模型可能不足以捕获数据中的所有模式（导致高的经验误差），而复杂的模型可能过拟合。
2. **验证**：为了估计泛化误差，我们经常使用验证集或交叉验证。这可以帮助我们选择那些既不是过度简化又不是过度复杂的模型。
3. **正则化**：技术如L1和L2正则化旨在防止过拟合，同时允许模型在训练数据上达到较低的经验误差。

总之，虽然经验误差是一个重要的指标，但在机器学习中，我们的主要目标是获得低的泛化误差。这可能需要牺牲一些经验误差，特别是在可能出现过拟合的情况下。

# 2.2 评估方法



## 2.2.1 留出法



## 2.2.2 交叉验证法



## 2.2.3 自助法



## 2.2.4 调参与最终模型



# 2.3 性能度量



## 2.3.1 错误率与精度



## 2.3.2 查准率、查全率与F1



## 2.3.3 ROC与AUC



## 2.3.4 代价敏感错误率与代价曲线



# 2.4 比较检验



## 2.4.1 假设检验



## 2.4.2 交叉验证t检验



## 2.4.3 McNemar检验



## 2.4.4 Friedman检验 与Nemenyi后续检验



# 2.5 偏差与方差